% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{rsolve_mdpo_sa}
\alias{rsolve_mdpo_sa}
\title{Solves a robust Markov decision process with state-action rectangular
ambiguity sets. The worst-case is computed across the outcomes and not
the actual transition probabilities.}
\usage{
rsolve_mdpo_sa(mdpo, discount, nature, nature_par, algorithm = "mppi",
  policy_fixed = NULL, maxresidual = 0.001, iterations = 10000L,
  timeout = 300, pack_actions = FALSE, output_tran = FALSE,
  show_progress = TRUE)
}
\arguments{
\item{algorithm}{One of "ppi", "mppi", "mpi", "vi", "vi_j", "pi". MPI may
may not converge}

\item{policy_fixed}{States for which the  policy should be fixed. This
should be a dataframe with columns idstate and idaction. The policy
is optimized only for states that are missing, and the fixed policy
is used otherwise}

\item{maxresidual}{Residual at which to terminate}

\item{iterations}{Maximum number of iterations}

\item{timeout}{Maximum number of secods for which to run the computation}

\item{pack_actions}{Whether to remove actions with no transition probabilities,
and rename others for the same state to prevent gaps. The policy
for the original actions can be recovered using ``action_map'' frame
in the result}

\item{output_tran}{Whether to construct and return a matrix of transition
probabilites and a vector of rewards}

\item{show_progress}{Whether to show a progress bar during the computation}
}
\value{
A list with value function policy and other values
}
\description{
NOTE: The algorithms  mpi and pi may cycle infinitely without converging to a solution,
when solving a robust MDP.
The algorithms ppi and mppi are guaranteed to converge to an optimal solution.
}
\details{
The options for nature and the corresponding nature_par are:
   \itemize{
        \item "evaru" a convex combination of expectation and V@R over
                transition probabilites. Uniform over all states and actions
                nature_par is a list with parameters (alpha, beta). The worst-case
                response is computed as:
                beta * var [z] + (1-beta) * E[z], where
                var is inf{x \in R : P[X <= x] >= alpha}, with alpha = 0 being the
                worst-case.
        \item "evaru" a convex combination of expectation and AV@R over
                transition probabilites. Uniform over states
                nature_par is a list with parameters (alpha, beta). The worst-case
                response is computed as:
                beta * var [z] + (1-beta) * E[z], where
                var is AVaR(z,alpha) =  1/alpha * ( E[X I{X <= x_a} ] + x_a (alpha - P[X <= x_a] )
                where I is the indicator function and
                x_a = inf{x \in R : P[X <= x] >= alpha} being the
                worst-case.
   }
}
